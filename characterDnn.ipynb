{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from VPython.Layer import Tensor, Convolution2D, Flatten, Dense, MaxPooling2D\n",
    "from VPython.NetWork import *\n",
    "import numpy as np\n",
    "from VPython.Activator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "Input = Tensor(28*28,1)\n",
    "out = Dense(neurons=100, activation='logistic', biasUsed=True)(Input)\n",
    "out = Dense(neurons=100, activation='logistic')(out)\n",
    "softmaxOut = Dense(neurons=12, activation=\"softmax\")(out)\n",
    "optimizer = SGD(lr=0.1, decay=1.0, clipvalue=10)\n",
    "\n",
    "model = Model(input=Input, output=softmaxOut)\n",
    "model.compileLoss(Cross_Entropy())\n",
    "model.compileRegular(None)\n",
    "model.compileOptimizer(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomImageDataset:\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = annotations_file\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        img1_path=os.path.join(self.img_dir,'1')\n",
    "        self.n = len(os.listdir(img1_path))\n",
    "        self.image_list=[]\n",
    "        for idx in range(self.n*12):\n",
    "            img_path = os.path.join(self.img_dir,str(int(idx/self.n )+ 1)+'/'+str(idx%self.n+1)+\".bmp\")\n",
    "            with Image.open(img_path) as im:\n",
    "                image = im.getdata()\n",
    "            label = int(idx/self.n )+ 1\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            if self.target_transform:\n",
    "                label = self.target_transform(label)\n",
    "            self.image_list.append((image, label))\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)*self.n\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.image_list[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['博', '学', '笃', '志', '切', '问', '近', '思', '自', '由', '无', '用']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transform(x):\n",
    "    x = np.array(x).reshape(28*28,1)\n",
    "    return x/255\n",
    "def target_transform(x):\n",
    "    res = np.zeros((12,1),dtype=np.float16)\n",
    "    res[int(x-1)][0] = 1.0\n",
    "    return res\n",
    "\n",
    "annotations='博学笃志切问近思自由无用'\n",
    "annotations=list(annotations)\n",
    "print(annotations)\n",
    "imageSet = CustomImageDataset(annotations,'./train/',transform,target_transform)\n",
    "image, label=imageSet[2212]\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.08333333333333333\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model:Model,Train):\n",
    "    nn=len(Train)\n",
    "    acc = 0\n",
    "    for i in range(nn):\n",
    "        image, label = Train[i]\n",
    "        input = model.predict(image)\n",
    "        if np.argmax(input) == np.argmax(label):\n",
    "            acc += 1\n",
    "    acc = acc/nn\n",
    "    print(\"acc\",acc)\n",
    "    \n",
    "evaluate(model,imageSet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "思\n",
      "思\n",
      "思\n",
      "思\n",
      "思\n",
      "思\n",
      "思\n",
      "思\n",
      "思\n",
      "思\n",
      "思\n",
      "思\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def myPrediction(model,path):\n",
    "    with Image.open(path) as im:\n",
    "        image = im.getdata()\n",
    "    image = np.array(image)/255\n",
    "    input = model.predict(image)\n",
    "    return annotations[np.argmax(input)]\n",
    "\n",
    "print(myPrediction(model,\"./train/1/10.bmp\"))\n",
    "print(myPrediction(model,\"./train/2/10.bmp\"))\n",
    "print(myPrediction(model,\"./train/3/10.bmp\"))\n",
    "print(myPrediction(model,\"./train/4/10.bmp\"))\n",
    "print(myPrediction(model,\"./train/5/10.bmp\"))\n",
    "print(myPrediction(model,\"./train/6/10.bmp\"))\n",
    "print(myPrediction(model,\"./train/7/10.bmp\"))\n",
    "print(myPrediction(model,\"./train/8/10.bmp\"))\n",
    "print(myPrediction(model,\"./train/9/10.bmp\"))\n",
    "print(myPrediction(model,\"./train/10/10.bmp\"))\n",
    "print(myPrediction(model,\"./train/11/10.bmp\"))\n",
    "print(myPrediction(model,\"./train/12/10.bmp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6696\n",
      "744\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "def fit(model:Model,Train,Test, epoch:int =1,batch_size: int = 1, log: bool = True):\n",
    "    nn=len(Train)\n",
    "    input = 0\n",
    "    sumloss = 0\n",
    "    loss = 0\n",
    "    error = False\n",
    "    lr = model.optimizer.lr\n",
    "    iteration = int(nn/batch_size)\n",
    "    print(\"iteration\",iteration)\n",
    "    lastLoss = 0\n",
    "    allLoss = 0.0\n",
    "    worse = 0\n",
    "    TrainAcc = 0\n",
    "    TestAcc = 0\n",
    "    for i in range(epoch):\n",
    "        TrainAcc = 0\n",
    "        TestAcc = 0\n",
    "        print(i)\n",
    "        testIndex = list(range(nn))\n",
    "        np.random.shuffle(testIndex)\n",
    "        lastLoss = allLoss\n",
    "        allLoss = 0.0\n",
    "        for j in range(iteration):\n",
    "            \n",
    "\n",
    "            sumloss=0.0\n",
    "            for k in range(batch_size):\n",
    "                testIndex0 = testIndex[j*batch_size+k]\n",
    "                image,label = Train[testIndex0]\n",
    "                input = model.predict(image)\n",
    "                derivation, loss = model.lossFunc(f=input, res=label)\n",
    "                if np.isnan(loss):\n",
    "                    error = True\n",
    "                    print(\"Error\")\n",
    "                    break\n",
    "                for item in model.layer[-1::-1]:\n",
    "                    derivation = item.feedBackward(derivation, model.optimizer.clipvalue)\n",
    "                    derivation = np.array(derivation)\n",
    "                if np.argmax(input) == np.argmax(label):\n",
    "                    TrainAcc = TrainAcc + 1\n",
    "                \n",
    "                sumloss = sumloss + loss\n",
    "                allLoss = allLoss + loss\n",
    "            for item in model.layer:\n",
    "                if error:\n",
    "                    item.abort()\n",
    "                    print(\"Error\")\n",
    "                    return\n",
    "                else:\n",
    "                    item.parameterUpdate(batch_size, lr, model.regularization)\n",
    "            # if xtest is not None and ytest is not None and step is not None:\n",
    "        for j in range(len(Test)):\n",
    "            image,label = Test[j]\n",
    "            input = model.predict(image)\n",
    "            if np.argmax(input) == np.argmax(label):\n",
    "                TestAcc = TestAcc +1\n",
    "        if allLoss > lastLoss:\n",
    "            worse = worse+1\n",
    "        else:\n",
    "            worse  = 0\n",
    "        if worse > 3:\n",
    "            lr = max(lr*0.9,0.001)\n",
    "        if log:\n",
    "            print(\"epoch=%d,loss = %.8f,trainAcc=%.8f,testAcc = %.8f\" % (i, allLoss/iteration/batch_size,TrainAcc/nn,TestAcc/len(Test)))\n",
    "        lr = max(lr * model.optimizer.decay,0.001)\n",
    "mylist = list(range(620))\n",
    "rate = 0.1\n",
    "\n",
    "Train = []\n",
    "Test = []\n",
    "for i in range(12):\n",
    "    np.random.shuffle(mylist)\n",
    "    for j in range(620):\n",
    "        if j < 620*rate:\n",
    "            Test.append(imageSet[i*620+mylist[j]])\n",
    "        else:\n",
    "            Train.append(imageSet[i*620+mylist[j]])\n",
    "\n",
    "print(len(Train))\n",
    "print(len(Test))\n",
    "for i in Test:\n",
    "    print(np.argmax(i[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 279\n",
      "0\n",
      "epoch=0,loss = 2.50120964,trainAcc=0.08751493,testAcc = 0.08333333\n",
      "1\n",
      "epoch=1,loss = 2.45159670,trainAcc=0.12246117,testAcc = 0.24327957\n",
      "2\n",
      "epoch=2,loss = 2.29307622,trainAcc=0.24313023,testAcc = 0.31182796\n",
      "3\n",
      "epoch=3,loss = 1.93984487,trainAcc=0.37320789,testAcc = 0.15322581\n",
      "4\n",
      "epoch=4,loss = 1.64632583,trainAcc=0.44997013,testAcc = 0.58467742\n",
      "5\n",
      "epoch=5,loss = 1.42384747,trainAcc=0.54375747,testAcc = 0.49193548\n",
      "6\n",
      "epoch=6,loss = 1.17608859,trainAcc=0.63172043,testAcc = 0.71370968\n",
      "7\n",
      "epoch=7,loss = 1.00877937,trainAcc=0.69190562,testAcc = 0.70698925\n",
      "8\n",
      "epoch=8,loss = 0.90789327,trainAcc=0.71505376,testAcc = 0.71236559\n",
      "9\n",
      "epoch=9,loss = 0.81897334,trainAcc=0.74940263,testAcc = 0.74327957\n",
      "10\n",
      "epoch=10,loss = 0.74795583,trainAcc=0.76403823,testAcc = 0.80376344\n",
      "11\n",
      "epoch=11,loss = 0.67888353,trainAcc=0.79316010,testAcc = 0.79569892\n",
      "12\n",
      "epoch=12,loss = 0.65384386,trainAcc=0.79525090,testAcc = 0.78494624\n",
      "13\n",
      "epoch=13,loss = 0.61077451,trainAcc=0.81332139,testAcc = 0.81854839\n",
      "14\n",
      "epoch=14,loss = 0.56441681,trainAcc=0.82407407,testAcc = 0.82930108\n",
      "15\n",
      "epoch=15,loss = 0.55322996,trainAcc=0.82646356,testAcc = 0.80510753\n",
      "16\n",
      "epoch=16,loss = 0.50970854,trainAcc=0.84692354,testAcc = 0.80645161\n",
      "17\n",
      "epoch=17,loss = 0.49713488,trainAcc=0.85020908,testAcc = 0.82930108\n",
      "18\n",
      "epoch=18,loss = 0.46670608,trainAcc=0.85618280,testAcc = 0.85080645\n",
      "19\n",
      "epoch=19,loss = 0.42462639,trainAcc=0.87380526,testAcc = 0.86290323\n",
      "20\n",
      "epoch=20,loss = 0.44457879,trainAcc=0.86364994,testAcc = 0.82930108\n",
      "21\n",
      "epoch=21,loss = 0.41161069,trainAcc=0.87604540,testAcc = 0.84408602\n",
      "22\n",
      "epoch=22,loss = 0.39243213,trainAcc=0.87873357,testAcc = 0.84139785\n",
      "23\n",
      "epoch=23,loss = 0.37536321,trainAcc=0.88679809,testAcc = 0.84005376\n",
      "24\n",
      "epoch=24,loss = 0.36314549,trainAcc=0.89262246,testAcc = 0.85887097\n",
      "25\n",
      "epoch=25,loss = 0.33877189,trainAcc=0.89874552,testAcc = 0.83064516\n",
      "26\n",
      "epoch=26,loss = 0.33314214,trainAcc=0.90053763,testAcc = 0.84811828\n",
      "27\n",
      "epoch=27,loss = 0.36193693,trainAcc=0.88903823,testAcc = 0.83870968\n",
      "28\n",
      "epoch=28,loss = 0.30712974,trainAcc=0.90501792,testAcc = 0.86424731\n",
      "29\n",
      "epoch=29,loss = 0.31049988,trainAcc=0.90815412,testAcc = 0.86693548\n",
      "30\n",
      "epoch=30,loss = 0.28867937,trainAcc=0.91830944,testAcc = 0.84677419\n",
      "31\n",
      "epoch=31,loss = 0.28112219,trainAcc=0.91875747,testAcc = 0.85887097\n",
      "32\n",
      "epoch=32,loss = 0.24971309,trainAcc=0.92876344,testAcc = 0.86693548\n",
      "33\n",
      "epoch=33,loss = 0.26132396,trainAcc=0.92084827,testAcc = 0.81720430\n",
      "34\n",
      "epoch=34,loss = 0.25761832,trainAcc=0.92338710,testAcc = 0.83064516\n",
      "35\n",
      "epoch=35,loss = 0.24133435,trainAcc=0.92980884,testAcc = 0.86021505\n",
      "36\n",
      "epoch=36,loss = 0.23777941,trainAcc=0.92727001,testAcc = 0.86155914\n",
      "37\n",
      "epoch=37,loss = 0.20854736,trainAcc=0.94056153,testAcc = 0.86021505\n",
      "38\n",
      "epoch=38,loss = 0.22551140,trainAcc=0.93115293,testAcc = 0.87096774\n",
      "39\n",
      "epoch=39,loss = 0.20796141,trainAcc=0.94071087,testAcc = 0.87768817\n",
      "40\n",
      "epoch=40,loss = 0.18693687,trainAcc=0.94459379,testAcc = 0.87096774\n",
      "41\n",
      "epoch=41,loss = 0.20943330,trainAcc=0.93488650,testAcc = 0.84811828\n",
      "42\n",
      "epoch=42,loss = 0.18505653,trainAcc=0.94489247,testAcc = 0.85080645\n",
      "43\n",
      "epoch=43,loss = 0.17778602,trainAcc=0.94862605,testAcc = 0.86693548\n",
      "44\n",
      "epoch=44,loss = 0.16152503,trainAcc=0.95191159,testAcc = 0.87096774\n",
      "45\n",
      "epoch=45,loss = 0.15151159,trainAcc=0.95788530,testAcc = 0.88172043\n",
      "46\n",
      "epoch=46,loss = 0.15686166,trainAcc=0.95415173,testAcc = 0.88172043\n",
      "47\n",
      "epoch=47,loss = 0.14975336,trainAcc=0.95743728,testAcc = 0.85080645\n",
      "48\n",
      "epoch=48,loss = 0.13998517,trainAcc=0.96072282,testAcc = 0.87768817\n",
      "49\n",
      "epoch=49,loss = 0.12695683,trainAcc=0.96460573,testAcc = 0.88172043\n",
      "50\n",
      "epoch=50,loss = 0.12006701,trainAcc=0.96684588,testAcc = 0.86693548\n",
      "51\n",
      "epoch=51,loss = 0.11784566,trainAcc=0.97057945,testAcc = 0.86962366\n",
      "52\n",
      "epoch=52,loss = 0.11731244,trainAcc=0.96923536,testAcc = 0.88978495\n",
      "53\n",
      "epoch=53,loss = 0.15602404,trainAcc=0.95922939,testAcc = 0.87634409\n",
      "54\n",
      "epoch=54,loss = 0.10174972,trainAcc=0.97505974,testAcc = 0.86021505\n",
      "55\n",
      "epoch=55,loss = 0.09722811,trainAcc=0.97640382,testAcc = 0.87768817\n",
      "56\n",
      "epoch=56,loss = 0.09690046,trainAcc=0.97700119,testAcc = 0.88037634\n",
      "57\n",
      "epoch=57,loss = 0.08753222,trainAcc=0.97849462,testAcc = 0.86827957\n",
      "58\n",
      "epoch=58,loss = 0.08040245,trainAcc=0.98327360,testAcc = 0.88037634\n",
      "59\n",
      "epoch=59,loss = 0.08882646,trainAcc=0.97774791,testAcc = 0.84677419\n",
      "60\n",
      "epoch=60,loss = 0.07696204,trainAcc=0.98297491,testAcc = 0.87634409\n",
      "61\n",
      "epoch=61,loss = 0.06834351,trainAcc=0.98745520,testAcc = 0.88037634\n",
      "62\n",
      "epoch=62,loss = 0.07011139,trainAcc=0.98551374,testAcc = 0.86155914\n",
      "63\n",
      "epoch=63,loss = 0.10801882,trainAcc=0.97386499,testAcc = 0.88172043\n",
      "64\n",
      "epoch=64,loss = 0.16103884,trainAcc=0.95594385,testAcc = 0.88306452\n",
      "65\n",
      "epoch=65,loss = 0.06396264,trainAcc=0.98581243,testAcc = 0.88575269\n",
      "66\n",
      "epoch=66,loss = 0.06336565,trainAcc=0.98730585,testAcc = 0.88709677\n",
      "67\n",
      "epoch=67,loss = 0.05416737,trainAcc=0.98954600,testAcc = 0.87768817\n",
      "68\n",
      "epoch=68,loss = 0.05538646,trainAcc=0.99029271,testAcc = 0.88978495\n",
      "69\n",
      "epoch=69,loss = 0.04827065,trainAcc=0.99148746,testAcc = 0.89247312\n",
      "70\n",
      "epoch=70,loss = 0.04970991,trainAcc=0.99163680,testAcc = 0.89650538\n",
      "71\n",
      "epoch=71,loss = 0.04395326,trainAcc=0.99253286,testAcc = 0.88709677\n",
      "72\n",
      "epoch=72,loss = 0.04434217,trainAcc=0.99253286,testAcc = 0.89381720\n",
      "73\n",
      "epoch=73,loss = 0.15540499,trainAcc=0.96236559,testAcc = 0.89247312\n",
      "74\n",
      "epoch=74,loss = 0.04192302,trainAcc=0.99327957,testAcc = 0.88844086\n",
      "75\n",
      "epoch=75,loss = 0.03855032,trainAcc=0.99447431,testAcc = 0.89247312\n",
      "76\n",
      "epoch=76,loss = 0.03637002,trainAcc=0.99432497,testAcc = 0.89381720\n",
      "77\n",
      "epoch=77,loss = 0.03530457,trainAcc=0.99462366,testAcc = 0.89247312\n",
      "78\n",
      "epoch=78,loss = 0.03520391,trainAcc=0.99432497,testAcc = 0.88978495\n",
      "79\n",
      "epoch=79,loss = 0.03113246,trainAcc=0.99611708,testAcc = 0.88575269\n",
      "80\n",
      "epoch=80,loss = 0.02945646,trainAcc=0.99656511,testAcc = 0.88037634\n",
      "81\n",
      "epoch=81,loss = 0.02850931,trainAcc=0.99611708,testAcc = 0.88575269\n",
      "82\n",
      "epoch=82,loss = 0.02603895,trainAcc=0.99656511,testAcc = 0.88440860\n",
      "83\n",
      "epoch=83,loss = 0.02626459,trainAcc=0.99626643,testAcc = 0.87903226\n",
      "84\n",
      "epoch=84,loss = 0.02492883,trainAcc=0.99716249,testAcc = 0.88709677\n",
      "85\n",
      "epoch=85,loss = 0.02316552,trainAcc=0.99746117,testAcc = 0.88440860\n",
      "86\n",
      "epoch=86,loss = 0.02474296,trainAcc=0.99641577,testAcc = 0.89650538\n",
      "87\n",
      "epoch=87,loss = 0.03353975,trainAcc=0.99283154,testAcc = 0.88844086\n",
      "88\n",
      "epoch=88,loss = 0.02218399,trainAcc=0.99701314,testAcc = 0.88844086\n",
      "89\n",
      "epoch=89,loss = 0.01831501,trainAcc=0.99850657,testAcc = 0.87096774\n",
      "90\n",
      "epoch=90,loss = 0.01840297,trainAcc=0.99895460,testAcc = 0.89650538\n",
      "91\n",
      "epoch=91,loss = 0.01732955,trainAcc=0.99910394,testAcc = 0.89112903\n",
      "92\n",
      "epoch=92,loss = 0.01654712,trainAcc=0.99865591,testAcc = 0.89112903\n",
      "93\n",
      "epoch=93,loss = 0.01627747,trainAcc=0.99895460,testAcc = 0.89112903\n",
      "94\n",
      "epoch=94,loss = 0.01520987,trainAcc=0.99910394,testAcc = 0.87500000\n",
      "95\n",
      "epoch=95,loss = 0.01528143,trainAcc=0.99865591,testAcc = 0.89112903\n",
      "96\n",
      "epoch=96,loss = 0.01404206,trainAcc=0.99925329,testAcc = 0.88978495\n",
      "97\n",
      "epoch=97,loss = 0.01393743,trainAcc=0.99925329,testAcc = 0.89112903\n",
      "98\n",
      "epoch=98,loss = 0.01334426,trainAcc=0.99940263,testAcc = 0.89112903\n",
      "99\n",
      "epoch=99,loss = 0.01267024,trainAcc=0.99925329,testAcc = 0.89516129\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fit(model,Train,Test,100,24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.8951612903225806\n",
      "[62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62]\n"
     ]
    }
   ],
   "source": [
    "evaluate(model,Test)\n",
    "sum =[0]*12\n",
    "for i in Test:\n",
    "    sum[np.argmax(i[1])]+=1\n",
    "print(sum)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
