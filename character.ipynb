{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from VPython.NetWork import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from alive_progress import alive_bar\n",
    "import time\n",
    "from tqdm import trange\n",
    "Input = Tensor(28, 28)\n",
    "out = Convolution2D(filters=4, kernel=(3, 3), activation='relu', biasUsed=True)(Input)\n",
    "out = MaxPooling2D((3,3))(out)\n",
    "out = Convolution2D(filters=8, kernel=(3, 3), activation='relu')(out)\n",
    "out = MaxPooling2D((3,3))(out)\n",
    "out = Flatten()(out)\n",
    "out = Dense(neurons=100, activation='logistic')(out)\n",
    "softmaxOut = Dense(neurons=12, activation=\"softmax\")(out)\n",
    "optimizer = SGD(lr=0.1, decay=1.0, clipvalue=10)\n",
    "model = Model(input=Input, output=softmaxOut)\n",
    "\n",
    "model.compileLoss(Cross_Entropy())\n",
    "model.compileRegular(L2Regularization(lamd=0.01))\n",
    "model.compileOptimizer(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomImageDataset:\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = annotations_file\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        img1_path=os.path.join(self.img_dir,'1')\n",
    "        self.n = len(os.listdir(img1_path))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)*self.n\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir,str(int(idx/self.n )+ 1)+'/'+str(idx%self.n+1)+\".bmp\")\n",
    "        with Image.open(img_path) as im:\n",
    "            image = im.getdata()\n",
    "        label = int(idx/self.n )+ 1\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['博', '学', '笃', '志', '切', '问', '近', '思', '自', '由', '无', '用']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,\n",
       "        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,\n",
       "        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,\n",
       "        1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
       "        0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transform(x):\n",
    "    x = np.array(x).reshape(28,28)\n",
    "    return x/255\n",
    "def target_transform(x):\n",
    "    res = np.zeros((12,1),dtype=np.float16)\n",
    "    res[int(x-1)][0] = 1.0\n",
    "    return res\n",
    "\n",
    "annotations='博学笃志切问近思自由无用'\n",
    "annotations=list(annotations)\n",
    "print(annotations)\n",
    "imageSet = CustomImageDataset(annotations,'./train/',transform,target_transform)\n",
    "image, label=imageSet[2212]\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6696\n",
      "744\n"
     ]
    }
   ],
   "source": [
    "def fit(model:Model,Train,Test, epoch:int =1,batch_size: int = 1, log: bool = True):\n",
    "    nn=len(Train)\n",
    "    input = 0\n",
    "    sumloss = 0\n",
    "    loss = 0\n",
    "    error = False\n",
    "    lr = model.optimizer.lr\n",
    "    iteration = int(nn/batch_size)\n",
    "    print(\"iteration\",iteration)\n",
    "    lastLoss = 0\n",
    "    allLoss = 0.0\n",
    "    worse = 0\n",
    "    TrainAcc = 0\n",
    "    TestAcc = 0\n",
    "    LossList = []\n",
    "    TrainAccList = []\n",
    "    TestAccList=[]\n",
    "    with alive_bar(epoch*iteration*batch_size,force_tty=True) as bar:\n",
    "        for i in range(epoch):\n",
    "            TrainAcc = 0\n",
    "            TestAcc = 0\n",
    "            print(i)\n",
    "            testIndex = list(range(nn))\n",
    "            np.random.shuffle(testIndex)\n",
    "            lastLoss = allLoss\n",
    "            allLoss = 0.0\n",
    "            for layer in model.layer:\n",
    "                layer.parameterDecay(0,0,model.regularization)#l2正则化\n",
    "            for j in range(iteration):\n",
    "\n",
    "                sumloss=0.0\n",
    "                for k in range(batch_size):\n",
    "                    testIndex0 = testIndex[j*batch_size+k]\n",
    "                    image,label = Train[testIndex0]\n",
    "                    input = model.predict(image)\n",
    "                    derivation, loss = model.lossFunc(f=input, res=label)\n",
    "                    if np.isnan(loss):\n",
    "                        error = True\n",
    "                        print(\"Error\")\n",
    "                        break\n",
    "                    for item in model.layer[-1::-1]:\n",
    "                        derivation = item.feedBackward(derivation)\n",
    "                        derivation = np.array(derivation)\n",
    "                    if np.argmax(input) == np.argmax(label):\n",
    "                        TrainAcc = TrainAcc + 1\n",
    "                    \n",
    "                    sumloss = sumloss + loss\n",
    "                    bar()\n",
    "\n",
    "                allLoss = allLoss + sumloss/batch_size\n",
    "                for item in model.layer:\n",
    "                    if error:\n",
    "                        item.abort()\n",
    "                        print(\"Error\")\n",
    "                        return\n",
    "                    else:\n",
    "                        item.parameterUpdate(batch_size, lr, model.regularization)\n",
    "                # if xtest is not None and ytest is not None and step is not None:\n",
    "            for j in range(len(Test)):\n",
    "                image,label = Test[j]\n",
    "                input = model.predict(image)\n",
    "                if np.argmax(input) == np.argmax(label):\n",
    "                    TestAcc = TestAcc +1\n",
    "            if allLoss > lastLoss:\n",
    "                worse = worse+1\n",
    "                \n",
    "            if worse > 3:\n",
    "                lr = max(lr*0.9,0.001)\n",
    "                worse  = 0\n",
    "            if log:\n",
    "                print(\"epoch=%d,loss = %.8f,trainAcc=%.8f,testAcc = %.8f\" % (i, allLoss/iteration,TrainAcc/nn,TestAcc/len(Test)))\n",
    "            lr = max(lr * model.optimizer.decay,0.001)\n",
    "            LossList.append(allLoss/iteration)\n",
    "            TrainAccList.append(TrainAcc/nn)\n",
    "            TestAccList.append(TestAcc/len(Test))\n",
    "            model.logModel(\"./model/character3newest.hdf5\")\n",
    "    import matplotlib.pyplot as plt\n",
    "    print(LossList)\n",
    "    plt.plot(list(range(len(LossList))),LossList)\n",
    "    plt.show()\n",
    "    plt.plot(list(range(len(TrainAccList))),TrainAccList,'-g')\n",
    "    plt.plot(list(range(len(TestAccList))),TestAccList,'-b')\n",
    "    plt.show()\n",
    "mylist = list(range(620))\n",
    "rate = 0.1\n",
    "\n",
    "Train = []\n",
    "Test = []\n",
    "for i in range(12):\n",
    "    np.random.shuffle(mylist)\n",
    "    for j in range(620):\n",
    "        if j < 620*rate:\n",
    "            Test.append(imageSet[i*620+mylist[j]])\n",
    "        else:\n",
    "            Train.append(imageSet[i*620+mylist[j]])\n",
    "\n",
    "print(len(Train))\n",
    "print(len(Test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 279\n",
      "on 0: 0                                                                         \n",
      "|                                        | ▄▂▂ 0/669600 [0%] in 42s (~0s, 0.0/s)"
     ]
    }
   ],
   "source": [
    "fit(model,Train,Test,100,24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m     acc \u001b[39m=\u001b[39m acc\u001b[39m/\u001b[39mnn\n\u001b[1;32m     11\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39macc\u001b[39m\u001b[39m\"\u001b[39m,acc)\n\u001b[0;32m---> 13\u001b[0m evaluate(model,Test)\n",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(model, Train)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(nn):\n\u001b[1;32m      6\u001b[0m     image, label \u001b[39m=\u001b[39m Train[i]\n\u001b[0;32m----> 7\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(image)\n\u001b[1;32m      8\u001b[0m     \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39margmax(\u001b[39minput\u001b[39m) \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39margmax(label):\n\u001b[1;32m      9\u001b[0m         acc \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m/workspaces/testCharacter/VPython/NetWork.py:92\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(\u001b[39minput\u001b[39m)\n\u001b[1;32m     91\u001b[0m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer:\n\u001b[0;32m---> 92\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m item\u001b[39m.\u001b[39;49mforward(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m     94\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m/workspaces/testCharacter/VPython/Layer.py:317\u001b[0m, in \u001b[0;36mConvolution2D.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    315\u001b[0m             k_h \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel[\u001b[39m0\u001b[39m]\n\u001b[1;32m    316\u001b[0m             k_w \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel[\u001b[39m1\u001b[39m]\n\u001b[0;32m--> 317\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresult[i, j, k] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49msum(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput[:, j:j \u001b[39m+\u001b[39;49m k_h, k:k \u001b[39m+\u001b[39;49m k_w] \u001b[39m*\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweights[i, :, :, :])\n\u001b[1;32m    319\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbiasUsed:\n\u001b[1;32m    320\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresult \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresult \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:2313\u001b[0m, in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2310\u001b[0m         \u001b[39mreturn\u001b[39;00m out\n\u001b[1;32m   2311\u001b[0m     \u001b[39mreturn\u001b[39;00m res\n\u001b[0;32m-> 2313\u001b[0m \u001b[39mreturn\u001b[39;00m _wrapreduction(a, np\u001b[39m.\u001b[39;49madd, \u001b[39m'\u001b[39;49m\u001b[39msum\u001b[39;49m\u001b[39m'\u001b[39;49m, axis, dtype, out, keepdims\u001b[39m=\u001b[39;49mkeepdims,\n\u001b[1;32m   2314\u001b[0m                       initial\u001b[39m=\u001b[39;49minitial, where\u001b[39m=\u001b[39;49mwhere)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:88\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     86\u001b[0m             \u001b[39mreturn\u001b[39;00m reduction(axis\u001b[39m=\u001b[39maxis, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 88\u001b[0m \u001b[39mreturn\u001b[39;00m ufunc\u001b[39m.\u001b[39;49mreduce(obj, axis, dtype, out, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpasskwargs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.logModel(\"./model/character3.hdf5\")\n",
    "def evaluate(model:Model,Train):\n",
    "    nn=len(Train)\n",
    "    acc = 0\n",
    "    for i in range(nn):\n",
    "        image, label = Train[i]\n",
    "        input = model.predict(image)\n",
    "        if np.argmax(input) == np.argmax(label):\n",
    "            acc += 1\n",
    "    acc = acc/nn\n",
    "    print(\"acc\",acc)\n",
    "    \n",
    "evaluate(model,Test)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
